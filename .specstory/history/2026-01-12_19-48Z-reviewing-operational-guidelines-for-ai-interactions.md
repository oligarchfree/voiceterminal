<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- vscode Session 7716f4a7-35ca-4853-af51-6ccd1c148be7 (2026-01-12 19:48Z) -->

# Reviewing operational guidelines for AI interactions (2026-01-12 19:48Z)

_**User (2026-01-12 19:51Z)**_

review ai-instructions.txt

---

_**Agent (model copilot/claude-sonnet-4.5)**_

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/ai-instructions.txt)</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/ai-instructions.txt)

</details>
</tool-use>

---

I'll review the `ai-instructions.txt` file for you. I've reviewed the `ai-instructions.txt` file. It contains 4 key directives for how you want me to operate:

1. **No unsolicited suggestions** - Only provide what's requested
2. **Succinct responses** - Keep answers brief and to the point
3. **No speculative refactoring** - Stop and ask for direction when confused rather than making large code changes
4. **Clarify when unclear** - Ask questions if instructions are ambiguous

These are clear operational guidelines for our interactions. The file is concise and well-structured.

---

_**User (2026-01-12 20:10Z)**_

review the html / js files in this directory, and provide a synopsis

---

_**Agent (model copilot/claude-sonnet-4.5)**_

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/index.html#1-1), lines 1 to 200</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/index.html#1-1), lines 1 to 200

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/server.js)</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/server.js)

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/intentProcessor.js)</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/intentProcessor.js)

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/intent.js)</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/intent.js)

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/stt.js#1-1), lines 1 to 200</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/stt.js#1-1), lines 1 to 200

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/hubitat.js)</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/hubitat.js)

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/stt.js#200-200), lines 200 to 457</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/stt.js#200-200), lines 200 to 457

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="copilot_readFile">
<details>
<summary>Tool use: **copilot_readFile** • Reading [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/index.html#200-200), lines 200 to 216</summary>


Read [](file:///Users/dijonmusk/Desktop/NEO_TERMINAL/VOICE_TERMINAL/index.html#200-200), lines 200 to 216

</details>
</tool-use>

---

## Synopsis

**Voice-controlled Hubitat home automation system** with speech recognition and intent routing:

### **`index.html`** - Main UI
- Device dropdown selector with manual ON/OFF controls
- Text command input for testing intent routing
- Voice controls with wake word "Zentra"
- Real-time transcription and command logging
- Loads scripts in sequence: hubitat → intentProcessor → intent → stt

### **`server.js`** - HTTPS Proxy Server
- Express server on port 8787 with self-signed SSL certificates
- Proxies `/hubitat/*` requests to Hubitat Maker API (192.168.68.67)
- Hides access token from client-side code
- Serves static files

### **`hubitat.js`** - Device Management
- Fetches devices from Maker API via proxy
- Classifies devices (switch/dimmer/fan/rgb_light)
- LocalStorage-based device registry with aliases
- Command execution (on/off/dimmer/etc.)
- Dropdown population & selection persistence

### **`intentProcessor.js`** - Text Normalization & Wake Detection
- **Normalization**: lowercases, strips punctuation, collapses whitespace
- **Fusion remap**: aliases ("et cetera" → "zentra", "lamb" → "lamp")
- **Wake word detection**: fuzzy matching with Levenshtein distance (≤2)
- **Modes**: wake-only vs wake+command vs active-mode
- Emits commands to `onVoiceCommand` callback

### **`intent.js`** - Intent Router
- Routes normalized text to `device_on` or `device_off` intents
- Phrase matching: "turn on", "lights on", "power off", etc.
- Ambiguity rejection (if both on/off detected)
- Executes via Hubitat API using selected device ID

### **`stt.js`** - Speech Recognition
- Uses Whisper Tiny model via Transformers.js
- **VAD**: RMS + frequency-band energy analysis
- **Audio processing**: highpass/lowpass filters, leveling, compression
- **Two parameter sets**: wake word (fast) vs active mode (higher quality)
- **Preroll/postroll** buffers for complete utterances
- Resamples to 16kHz, processes segments, sends to intentProcessor

### **Architecture Flow**
1. User says "Zentra turn on the light"
2. `stt.js` captures audio → transcribes → sends to `intentProcessor.js`
3. `intentProcessor.js` normalizes, applies fusion remaps, detects wake word, emits command
4. `onVoiceCommand` in HTML calls `intent.js` to route text
5. `intent.js` identifies `device_on` intent, executes via `hubitat.js`
6. `hubitat.js` sends command to proxy → Hubitat hub → device turns on

---

